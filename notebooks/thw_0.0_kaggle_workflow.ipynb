{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Data Science Project Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ShuaiW/how-to-kaggle\n",
    "\n",
    "1. Divide Forces\n",
    "    - Determine jobs that each team member will have\n",
    "2. Data Setup\n",
    "    - Get the data\n",
    "    - Store the data\n",
    "3. Literature Review\n",
    "    - See how people solved similar problems\n",
    "4. Establish an Evaluation Framework\n",
    "    - Determine metrics to use (accuracy, r2, mean_squared_error, area under the ROC curve, etc.)\n",
    "    - Determine cross validation strategy (Nested Cross Validation seems like a winner)\n",
    "5. Exploratory Data Analysis\n",
    "6. Preprocessing\n",
    "    1. Data cleaning: (fill in missing values, smooth noisy data, identify or remove outliers, resolve inconsistencies)\n",
    "    2. Data integration: use multiple data sources and join/merge data\n",
    "    3. Data transformation: normalize, aggregate, and embed (word)\n",
    "    4. Data reduction: reduce the volume of data but produce the same or similar analytical results (e.g. PCA)\n",
    "    5. Data discretization: replace numerical attributes with nominal/discrete ones (bin continuous feature for instance)\n",
    "7. Feature Engineering\n",
    "    1. Feature selection\n",
    "        1. Removing features with low variance\n",
    "        2. Univariate feature selection\n",
    "        3. Recursive feature elimination\n",
    "        4. Selecting from model\n",
    "    2. Feature creation\n",
    "        1. This is where we create new & novel features. Here are some examples of potential features to create in any given model:\n",
    "            1. Add zero_count for each row\n",
    "            2. Separate date into year, month, day, weekday, or weekend, etc.\n",
    "            3. Add percentile change from feature to feature (or other interactions among features)\n",
    "8. Model(s) Tuning\n",
    "    1. Use gridsearch style algorithms to search the hyperparameter space for the best set of parameters\n",
    "    2. Use something like hyperopt to optimize parameters\n",
    "    3. Use something like TPOT\n",
    "9. Ensemble\n",
    "    1. Combine models to optimize performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Problems\n",
    "1. Exploratory Data Analysis\n",
    "    1. Target Variable Analysis\n",
    "        1. Basic distribution\n",
    "        2. Are the classes imbalanced?\n",
    "    2. Null Counts/Fraction\n",
    "        1. Nulls by column\n",
    "        2. Nulls by row\n",
    "        3. Nulls by label (by row and/or column)\n",
    "        4. Determine if there's an obvious value that the Null's represent (i.e. like in the Iowa housing problem where null's had a specific value in the lookup table)\n",
    "    3. Count of 0s (if it's unclear what a 0 represents)\n",
    "    4. Univariate analyses\n",
    "        1. Distributions or value counts for each of the individual variables (if the number of variables is small enough)\n",
    "        2. Plots of the histograms of the different variables\n",
    "            1. These can be plotted on log scales if the range of values is too great.\n",
    "        3. Outlier analysis\n",
    "            1. Calculate z-scores or robust zscores\n",
    "    6. Contingency tables \n",
    "2. Model Preprocessing\n",
    "    1. Null value imputation\n",
    "    2. Categorical variable encoding\n",
    "    3. Transforms\n",
    "    4. Etc.\n",
    "3. Model building\n",
    "    1. Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping track of models\n",
    "\n",
    "Two possible paths. One with a lot of overhead (which will be used on actual work projects), which separates the tasks into individual files/scripts.\n",
    "\n",
    "The second one is to streamline the process a bit for quicker iteration. \n",
    "\n",
    "1. First notebook/script gets the data (if anything needs to be downloaded or whatever)\n",
    "    - Combines external data if needed\n",
    "    - Takes data from raw data folder & external sources folder, and puts outputs in interim data folder\n",
    "    \n",
    "2. Second notebook/series of notebooks (2.0-2.9) does the EDA\n",
    "    - No file outputs other than charts and visualizations\n",
    "    - Some feature engineering will occur in this stage, so some of the outputs might be functions to create the features which are applied in the preprocessing/feature engineering step\n",
    "    \n",
    "3. (3.0-3.9) does preprocessing/feature engineering. These two tasks are intertwined and should be done simultaneously.\n",
    "    - Inputs are the files from the interim folder\n",
    "    - Outputs to the processed data folder\n",
    "    \n",
    "4. (4.0-4.9) trains and tunes models\n",
    "    - Inputs are the processed data files\n",
    "    - Outputs are:\n",
    "        - The serialized submissions for the kaggle competition\n",
    "        - The similarly serialized model pickle files\n",
    "        - A model summary document (references the training data used, the python source code used, cross-validation score obtained on training data, possibly hyperparameters, etc.)\n",
    "  \n",
    "5. (5.0-5.9) combines/ensembles models\n",
    "    - Inputs are the models\n",
    "    - Outputs are the same as the previous steps outputs\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
